import urllib.request
from urllib.parse import urlparse
import re #æ­£åˆ™
import os
from datetime import datetime

# æ‰§è¡Œå¼€å§‹æ—¶é—´
timestart = datetime.now()
# æŠ¥æ—¶
print(f"time: {datetime.now().strftime("%Y%m%d_%H_%M_%S")}")
# å®šä¹‰è¦è®¿é—®çš„å¤šä¸ªURL
urls = [
    'https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u',
    'https://raw.githubusercontent.com/joevess/IPTV/main/iptv.m3u8',
    'https://raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt',
    'https://raw.githubusercontent.com/Guovin/TV/gd/result.txt', #æ¯å¤©è‡ªåŠ¨æ›´æ–°1æ¬¡
    'https://raw.githubusercontent.com/ssili126/tv/main/itvlist.txt', #æ¯å¤©è‡ªåŠ¨æ›´æ–°1æ¬¡
    'https://m3u.ibert.me/txt/fmml_ipv6.txt',
    'https://m3u.ibert.me/txt/ycl_iptv.txt',
    'https://m3u.ibert.me/txt/y_g.txt',
    'https://m3u.ibert.me/txt/j_home.txt',
    'https://raw.githubusercontent.com/gaotianliuyun/gao/master/list.txt',
    'https://gitee.com/xxy002/zhiboyuan/raw/master/zby.txt',
    'https://raw.githubusercontent.com/mlvjfchen/TV/main/iptv_list.txt', #æ¯å¤©æ—©æ™šå„è‡ªåŠ¨æ›´æ–°1æ¬¡ 2024-06-03 17:50
    'https://raw.githubusercontent.com/fenxp/iptv/main/live/ipv6.txt',  #1å°æ—¶è‡ªåŠ¨æ›´æ–°1æ¬¡11:11 2024/05/13
    'https://raw.githubusercontent.com/fenxp/iptv/main/live/tvlive.txt', #1å°æ—¶è‡ªåŠ¨æ›´æ–°1æ¬¡11:11 2024/05/13
    'https://raw.githubusercontent.com/zwc456baby/iptv_alive/master/live.txt',  #æ¯å¤©è‡ªåŠ¨æ›´æ–°1æ¬¡ 2024-06-24 16:37
    'https://gitlab.com/p2v5/wangtv/-/raw/main/lunbo.txt',
    'https://raw.githubusercontent.com/PizazzGY/TVBox/main/live.txt',  #ADD 2024-07-22 13:50
    'https://raw.githubusercontent.com/wwb521/live/main/tv.m3u',  #ADD 2024-08-05 æ¯10å¤©æ›´æ–°ä¸€æ¬¡
    'https://gitcode.net/MZ011/BHJK/-/raw/master/BHZB1.txt',  #ADD 2024-08-05 
    #'https://raw.githubusercontent.com/yuanzl77/IPTV/main/live.txt',   #ADD 2024-08-05 æ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼Œé‡å¤ªå¤šè½¬åˆ°blacklistå¤„ç†
    'http://47.99.102.252/live.txt' #ADD 2024-08-05 
    
]

#read BlackList 2024-06-17 15:02
def read_blacklist_from_txt(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    BlackList = [line.split(',')[1].strip() for line in lines if ',' in line]
    return BlackList

blacklist_auto=read_blacklist_from_txt('blacklist/blacklist_auto.txt') 
blacklist_manual=read_blacklist_from_txt('blacklist/blacklist_manual.txt') 
# combined_blacklist = list(set(blacklist_auto + blacklist_manual))
combined_blacklist = set(blacklist_auto + blacklist_manual)  #listæ˜¯ä¸ªåˆ—è¡¨ï¼Œsetæ˜¯ä¸ªé›†åˆï¼Œæ®è¯´æ£€ç´¢é€Ÿåº¦é›†åˆè¦å¿«å¾ˆå¤šã€‚2024-08-08

# å®šä¹‰å¤šä¸ªå¯¹è±¡ç”¨äºå­˜å‚¨ä¸åŒå†…å®¹çš„è¡Œæ–‡æœ¬
sh_lines = []
ys_lines = [] #CCTV
ws_lines = [] #å«è§†é¢‘é“
ty_lines = [] #ä½“è‚²é¢‘é“
dy_lines = []
dsj_lines = []
gat_lines = [] #æ¸¯æ¾³å°
gj_lines = [] #å›½é™…å°
jlp_lines = [] #è®°å½•ç‰‡
dhp_lines = [] #åŠ¨ç”»ç‰‡
xq_lines = [] #æˆæ›²
js_lines = [] #è§£è¯´
cw_lines = [] #æ˜¥æ™š
mx_lines = [] #æ˜æ˜Ÿ
ztp_lines = [] #ä¸»é¢˜ç‰‡
zy_lines = [] #ç»¼è‰ºé¢‘é“
yy_lines = [] #éŸ³ä¹é¢‘é“
game_lines = [] #æ¸¸æˆé¢‘é“
radio_lines = [] #æ”¶éŸ³æœºé¢‘é“

zj_lines = [] #åœ°æ–¹å°-æµ™æ±Ÿé¢‘é“
jsu_lines = [] #åœ°æ–¹å°-æ±Ÿè‹é¢‘é“
gd_lines = [] #åœ°æ–¹å°-å¹¿ä¸œé¢‘é“
hn_lines = [] #åœ°æ–¹å°-æ¹–å—é¢‘é“
ah_lines = [] #åœ°æ–¹å°-å®‰å¾½é¢‘é“
hain_lines = [] #åœ°æ–¹å°-æµ·å—é¢‘é“
nm_lines = [] #åœ°æ–¹å°-å†…è’™é¢‘é“
hb_lines = [] #åœ°æ–¹å°-æ¹–åŒ—é¢‘é“
ln_lines = [] #åœ°æ–¹å°-è¾½å®é¢‘é“
sx_lines = [] #åœ°æ–¹å°-é™•è¥¿é¢‘é“
shanxi_lines = [] #åœ°æ–¹å°-å±±è¥¿é¢‘é“
shandong_lines = [] #åœ°æ–¹å°-å±±ä¸œé¢‘é“
yunnan_lines = [] #åœ°æ–¹å°-äº‘å—é¢‘é“


##################ã€2024-07-30 18:04:56ã€‘
bj_lines = [] #åœ°æ–¹å°-åŒ—äº¬é¢‘é“
cq_lines = [] #åœ°æ–¹å°-é‡åº†é¢‘é“
fj_lines = [] #åœ°æ–¹å°-ç¦å»ºé¢‘é“
gs_lines = [] #åœ°æ–¹å°-ç”˜è‚ƒé¢‘é“
gx_lines = [] #åœ°æ–¹å°-å¹¿è¥¿é¢‘é“
gz_lines = [] #åœ°æ–¹å°-è´µå·é¢‘é“
heb_lines = [] #åœ°æ–¹å°-æ²³åŒ—é¢‘é“
hen_lines = [] #åœ°æ–¹å°-æ²³å—é¢‘é“
hlj_lines = [] #åœ°æ–¹å°-é»‘é¾™æ±Ÿé¢‘é“
jl_lines = [] #åœ°æ–¹å°-å‰æ—é¢‘é“
jx_lines = [] #åœ°æ–¹å°-æ±Ÿè¥¿é¢‘é“
nx_lines = [] #åœ°æ–¹å°-å®å¤é¢‘é“
qh_lines = [] #åœ°æ–¹å°-é’æµ·é¢‘é“
sc_lines = [] #åœ°æ–¹å°-å››å·é¢‘é“
tj_lines = [] #åœ°æ–¹å°-å¤©æ´¥é¢‘é“
xj_lines = [] #åœ°æ–¹å°-æ–°ç–†é¢‘é“

zb_lines = [] #ç›´æ’­ä¸­å›½
mtv_lines = [] #MTV

Olympics_2024_Paris_lines = [] #Paris_2024_Olympics  Olympics_2024_Paris ADD 2024-08-05
# favorite_lines = []

other_lines = []

def process_name_string(input_str):
    parts = input_str.split(',')
    processed_parts = []
    for part in parts:
        processed_part = process_part(part)
        processed_parts.append(processed_part)
    result_str = ','.join(processed_parts)
    return result_str

def process_part(part_str):
    # å¤„ç†é€»è¾‘
    if "CCTV" in part_str  and "://" not in part_str:
        part_str=part_str.replace("IPV6", "")  #å…ˆå‰”é™¤IPV6å­—æ ·
        part_str=part_str.replace("PLUS", "+")  #æ›¿æ¢PLUS
        part_str=part_str.replace("1080", "")  #æ›¿æ¢1080
        filtered_str = ''.join(char for char in part_str if char.isdigit() or char == 'K' or char == '+')
        if not filtered_str.strip(): #å¤„ç†ç‰¹æ®Šæƒ…å†µï¼Œå¦‚æœå‘ç°æ²¡æœ‰æ‰¾åˆ°é¢‘é“æ•°å­—è¿”å›åŸåç§°
            filtered_str=part_str.replace("CCTV", "")

        if len(filtered_str) > 2 and re.search(r'4K|8K', filtered_str):   # ç‰¹æ®Šå¤„ç†CCTVä¸­éƒ¨åˆ†4Kå’Œ8Kåç§°
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢ï¼Œåˆ é™¤4Kæˆ–8Kåé¢çš„å­—ç¬¦ï¼Œå¹¶ä¸”ä¿ç•™4Kæˆ–8K
            filtered_str = re.sub(r'(4K|8K).*', r'\1', filtered_str)
            if len(filtered_str) > 2: 
                # ç»™4Kæˆ–8Kæ·»åŠ æ‹¬å·
                filtered_str = re.sub(r'(4K|8K)', r'(\1)', filtered_str)

        return "CCTV"+filtered_str 
        
    elif "å«è§†" in part_str:
        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼ŒåŒ¹é…â€œå«è§†â€åé¢çš„å†…å®¹
        pattern = r'å«è§†ã€Œ.*ã€'
        # ä½¿ç”¨subå‡½æ•°æ›¿æ¢åŒ¹é…çš„å†…å®¹ä¸ºç©ºå­—ç¬¦ä¸²
        result_str = re.sub(pattern, 'å«è§†', part_str)
        return result_str
    
    return part_str

# å‡†å¤‡æ”¯æŒm3uæ ¼å¼
def get_url_file_extension(url):
    # è§£æURL
    parsed_url = urlparse(url)
    # è·å–è·¯å¾„éƒ¨åˆ†
    path = parsed_url.path
    # æå–æ–‡ä»¶æ‰©å±•å
    extension = os.path.splitext(path)[1]
    return extension

def convert_m3u_to_txt(m3u_content):
    # åˆ†è¡Œå¤„ç†
    lines = m3u_content.split('\n')
    
    # ç”¨äºå­˜å‚¨ç»“æœçš„åˆ—è¡¨
    txt_lines = []
    
    # ä¸´æ—¶å˜é‡ç”¨äºå­˜å‚¨é¢‘é“åç§°
    channel_name = ""
    
    for line in lines:
        # è¿‡æ»¤æ‰ #EXTM3U å¼€å¤´çš„è¡Œ
        if line.startswith("#EXTM3U"):
            continue
        # å¤„ç† #EXTINF å¼€å¤´çš„è¡Œ
        if line.startswith("#EXTINF"):
            # è·å–é¢‘é“åç§°ï¼ˆå‡è®¾é¢‘é“åç§°åœ¨å¼•å·åï¼‰
            channel_name = line.split(',')[-1].strip()
        # å¤„ç† URL è¡Œ
        elif line.startswith("http"):
            txt_lines.append(f"{channel_name},{line.strip()}")
    
    # å°†ç»“æœåˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä»¥æ¢è¡Œç¬¦åˆ†éš”
    return '\n'.join(txt_lines)

# åœ¨listæ˜¯å¦å·²ç»å­˜åœ¨url 2024-07-22 11:18
def check_url_existence(data_list, url):
    """
    Check if a given URL exists in a list of data.

    :param data_list: List of strings containing the data
    :param url: The URL to check for existence
    :return: True if the URL exists in the list, otherwise False
    """
    # Extract URLs from the data list
    urls = [item.split(',')[1] for item in data_list]
    return url not in urls #å¦‚æœä¸å­˜åœ¨åˆ™è¿”å›trueï¼Œéœ€è¦

# åˆ†å‘ç›´æ’­æºï¼Œå½’ç±»ï¼ŒæŠŠè¿™éƒ¨åˆ†ä»process_urlå‰¥ç¦»å‡ºæ¥ï¼Œä¸ºä»¥ååŠ å…¥whitelistæºæ¸…å•åšå‡†å¤‡ã€‚
def process_channel_line(line):
    if  "#genre#" not in line and "," in line and "://" in line:
        channel_name=line.split(',')[0].strip()
        channel_address=line.split(',')[1].strip()
        if channel_address not in combined_blacklist: # åˆ¤æ–­å½“å‰æºæ˜¯å¦åœ¨blacklistä¸­
            # æ ¹æ®è¡Œå†…å®¹åˆ¤æ–­å­˜å…¥å“ªä¸ªå¯¹è±¡ï¼Œå¼€å§‹åˆ†å‘
            if "CCTV" in channel_name and check_url_existence(ys_lines, channel_address) : #å¤®è§†é¢‘é“
                ys_lines.append(process_name_string(line.strip()))
            elif channel_name in Olympics_2024_Paris_dictionary and check_url_existence(Olympics_2024_Paris_lines, channel_address): #å¥¥è¿é¢‘é“ ADD 2024-08-05
                Olympics_2024_Paris_lines.append(process_name_string(line.strip()))
            elif channel_name in ws_dictionary and check_url_existence(ws_lines, channel_address): #å«è§†é¢‘é“
                ws_lines.append(process_name_string(line.strip()))
            elif channel_name in ty_dictionary and check_url_existence(ty_lines, channel_address):  #ä½“è‚²é¢‘é“
                ty_lines.append(process_name_string(line.strip()))
            elif channel_name in dy_dictionary and check_url_existence(dy_lines, channel_address):  #ç”µå½±é¢‘é“
                dy_lines.append(process_name_string(line.strip()))
            elif channel_name in dsj_dictionary and check_url_existence(dsj_lines, channel_address):  #ç”µè§†å‰§é¢‘é“
                dsj_lines.append(process_name_string(line.strip()))
            elif channel_name in sh_dictionary and check_url_existence(sh_lines, channel_address):  #ä¸Šæµ·é¢‘é“
                sh_lines.append(process_name_string(line.strip()))
            elif channel_name in gat_dictionary and check_url_existence(gat_lines, channel_address):  #æ¸¯æ¾³å°
                gat_lines.append(process_name_string(line.strip()))
            elif channel_name in gj_dictionary and check_url_existence(gj_lines, channel_address):  #å›½é™…å°
                gj_lines.append(process_name_string(line.strip()))
            elif channel_name in jlp_dictionary and check_url_existence(jlp_lines, channel_address):  #çºªå½•ç‰‡
                jlp_lines.append(process_name_string(line.strip()))
            elif channel_name in dhp_dictionary and check_url_existence(dhp_lines, channel_address):  #åŠ¨ç”»ç‰‡
                dhp_lines.append(process_name_string(line.strip()))
            elif channel_name in xq_dictionary and check_url_existence(xq_lines, channel_address):  #æˆæ›²
                xq_lines.append(process_name_string(line.strip()))
            elif channel_name in js_dictionary and check_url_existence(js_lines, channel_address):  #è§£è¯´
                js_lines.append(process_name_string(line.strip()))
            elif channel_name in cw_dictionary and check_url_existence(cw_lines, channel_address):  #æ˜¥æ™š
                cw_lines.append(process_name_string(line.strip()))
            elif channel_name in mx_dictionary and check_url_existence(mx_lines, channel_address):  #æ˜æ˜Ÿ
                mx_lines.append(process_name_string(line.strip()))
            elif channel_name in ztp_dictionary and check_url_existence(ztp_lines, channel_address):  #ä¸»é¢˜ç‰‡
                ztp_lines.append(process_name_string(line.strip()))
            elif channel_name in zy_dictionary and check_url_existence(zy_lines, channel_address):  #ç»¼è‰ºé¢‘é“
                zy_lines.append(process_name_string(line.strip()))
            elif channel_name in yy_dictionary and check_url_existence(yy_lines, channel_address):  #éŸ³ä¹é¢‘é“
                yy_lines.append(process_name_string(line.strip()))
            elif channel_name in game_dictionary and check_url_existence(game_lines, channel_address):  #æ¸¸æˆé¢‘é“
                game_lines.append(process_name_string(line.strip()))
            elif channel_name in radio_dictionary and check_url_existence(radio_lines, channel_address):  #æ”¶éŸ³æœºé¢‘é“
                radio_lines.append(process_name_string(line.strip()))
            elif channel_name in zj_dictionary and check_url_existence(zj_lines, channel_address):  #åœ°æ–¹å°-æµ™æ±Ÿé¢‘é“
                zj_lines.append(process_name_string(line.strip()))
            elif channel_name in jsu_dictionary and check_url_existence(jsu_lines, channel_address):  #åœ°æ–¹å°-æ±Ÿè‹é¢‘é“
                jsu_lines.append(process_name_string(line.strip()))
            elif channel_name in gd_dictionary and check_url_existence(gd_lines, channel_address):  #åœ°æ–¹å°-å¹¿ä¸œé¢‘é“
                gd_lines.append(process_name_string(line.strip()))
            elif channel_name in hn_dictionary and check_url_existence(hn_lines, channel_address):  #åœ°æ–¹å°-æ¹–å—é¢‘é“
                hn_lines.append(process_name_string(line.strip()))
            elif channel_name in hb_dictionary and check_url_existence(hb_lines, channel_address):  #åœ°æ–¹å°-æ¹–åŒ—é¢‘é“
                hb_lines.append(process_name_string(line.strip()))
            elif channel_name in ah_dictionary and check_url_existence(ah_lines, channel_address):  #åœ°æ–¹å°-å®‰å¾½é¢‘é“
                ah_lines.append(process_name_string(line.strip()))
            elif channel_name in hain_dictionary and check_url_existence(hain_lines, channel_address):  #åœ°æ–¹å°-æµ·å—é¢‘é“
                hain_lines.append(process_name_string(line.strip()))
            elif channel_name in nm_dictionary and check_url_existence(nm_lines, channel_address):  #åœ°æ–¹å°-å†…è’™é¢‘é“
                nm_lines.append(process_name_string(line.strip()))
            elif channel_name in ln_dictionary and check_url_existence(ln_lines, channel_address):  #åœ°æ–¹å°-è¾½å®é¢‘é“
                ln_lines.append(process_name_string(line.strip()))
            elif channel_name in sx_dictionary and check_url_existence(sx_lines, channel_address):  #åœ°æ–¹å°-é™•è¥¿é¢‘é“
                sx_lines.append(process_name_string(line.strip()))
            elif channel_name in shanxi_dictionary and check_url_existence(shanxi_lines, channel_address):  #åœ°æ–¹å°-å±±è¥¿é¢‘é“
                shanxi_lines.append(process_name_string(line.strip()))
            elif channel_name in shandong_dictionary and check_url_existence(shandong_lines, channel_address):  #åœ°æ–¹å°-å±±ä¸œé¢‘é“
                shandong_lines.append(process_name_string(line.strip()))
            elif channel_name in yunnan_dictionary and check_url_existence(yunnan_lines, channel_address):  #åœ°æ–¹å°-äº‘å—é¢‘é“
                yunnan_lines.append(process_name_string(line.strip()))
            elif channel_name in bj_dictionary and check_url_existence(bj_lines, channel_address):  #åœ°æ–¹å°-åŒ—äº¬é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                bj_lines.append(process_name_string(line.strip()))
            elif channel_name in cq_dictionary and check_url_existence(cq_lines, channel_address):  #åœ°æ–¹å°-é‡åº†é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                cq_lines.append(process_name_string(line.strip()))
            elif channel_name in fj_dictionary and check_url_existence(fj_lines, channel_address):  #åœ°æ–¹å°-ç¦å»ºé¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                            fj_lines.append(process_name_string(line.strip()))
            elif channel_name in gs_dictionary and check_url_existence(gs_lines, channel_address):  #åœ°æ–¹å°-ç”˜è‚ƒé¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                gs_lines.append(process_name_string(line.strip()))
            elif channel_name in gx_dictionary and check_url_existence(gx_lines, channel_address):  #åœ°æ–¹å°-å¹¿è¥¿é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                gx_lines.append(process_name_string(line.strip()))
            elif channel_name in gz_dictionary and check_url_existence(gz_lines, channel_address):  #åœ°æ–¹å°-è´µå·é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                gz_lines.append(process_name_string(line.strip()))
            elif channel_name in heb_dictionary and check_url_existence(heb_lines, channel_address):  #åœ°æ–¹å°-æ²³åŒ—é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                heb_lines.append(process_name_string(line.strip()))
            elif channel_name in hen_dictionary and check_url_existence(hen_lines, channel_address):  #åœ°æ–¹å°-æ²³å—é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                hen_lines.append(process_name_string(line.strip()))
            elif channel_name in hlj_dictionary and check_url_existence(hlj_lines, channel_address):  #åœ°æ–¹å°-é»‘é¾™æ±Ÿé¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                hlj_lines.append(process_name_string(line.strip()))
            elif channel_name in jl_dictionary and check_url_existence(jl_lines, channel_address):  #åœ°æ–¹å°-å‰æ—é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                jl_lines.append(process_name_string(line.strip()))
            elif channel_name in nx_dictionary and check_url_existence(nx_lines, channel_address):  #åœ°æ–¹å°-å®å¤é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                nx_lines.append(process_name_string(line.strip()))
            elif channel_name in jx_dictionary and check_url_existence(jx_lines, channel_address):  #åœ°æ–¹å°-æ±Ÿè¥¿é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                jx_lines.append(process_name_string(line.strip()))
            elif channel_name in qh_dictionary and check_url_existence(qh_lines, channel_address):  #åœ°æ–¹å°-é’æµ·é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                qh_lines.append(process_name_string(line.strip()))
            elif channel_name in sc_dictionary and check_url_existence(sc_lines, channel_address):  #åœ°æ–¹å°-å››å·é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                sc_lines.append(process_name_string(line.strip()))
            elif channel_name in tj_dictionary and check_url_existence(tj_lines, channel_address):  #åœ°æ–¹å°-å¤©æ´¥é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                tj_lines.append(process_name_string(line.strip()))
            elif channel_name in xj_dictionary and check_url_existence(xj_lines, channel_address):  #åœ°æ–¹å°-æ–°ç–†é¢‘é“ ADDã€2024-07-30 20:52:53ã€‘
                xj_lines.append(process_name_string(line.strip()))
            elif channel_name in zb_dictionary and check_url_existence(zb_lines, channel_address):  #ç›´æ’­ä¸­å›½
                zb_lines.append(process_name_string(line.strip()))
            elif channel_name in mtv_dictionary and check_url_existence(mtv_lines, channel_address):  #MTV
                mtv_lines.append(process_name_string(line.strip()))
            else:
                other_lines.append(line.strip())


def process_url(url):
    try:
        other_lines.append("â—†â—†â—†ã€€"+url)  # å­˜å…¥other_linesä¾¿äºcheck 2024-08-02 10:41
        # æ‰“å¼€URLå¹¶è¯»å–å†…å®¹
        with urllib.request.urlopen(url) as response:
            # ä»¥äºŒè¿›åˆ¶æ–¹å¼è¯»å–æ•°æ®
            data = response.read()
            # å°†äºŒè¿›åˆ¶æ•°æ®è§£ç ä¸ºå­—ç¬¦ä¸²
            text = data.decode('utf-8')
            channel_name=""
            channel_address=""

            #å¤„ç†m3uå’Œm3u8ï¼Œæå–channel_nameå’Œchannel_address
            if get_url_file_extension(url)==".m3u" or get_url_file_extension(url)==".m3u8":
                text=convert_m3u_to_txt(text)

            # é€è¡Œå¤„ç†å†…å®¹
            lines = text.split('\n')
            print(f"è¡Œæ•°: {len(lines)}")
            for line in lines:
                process_channel_line(line) # æ¯è¡ŒæŒ‰ç…§è§„åˆ™è¿›è¡Œåˆ†å‘
            
            other_lines.append('\n') #æ¯ä¸ªurlå¤„ç†å®Œæˆåï¼Œåœ¨other_linesåŠ ä¸ªå›è½¦ 2024-08-02 10:46

    except Exception as e:
        print(f"å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")


current_directory = os.getcwd()  #å‡†å¤‡è¯»å–txt

#è¯»å–æ–‡æœ¬æ–¹æ³•
def read_txt_to_array(file_name):
    try:
        with open(file_name, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            lines = [line.strip() for line in lines]
            return lines
    except FileNotFoundError:
        print(f"File '{file_name}' not found.")
        return []
    except Exception as e:
        print(f"An error occurred: {e}")
        return []
#è¯»å–æ–‡æœ¬
ys_dictionary=read_txt_to_array('ä¸»é¢‘é“/CCTV.txt') #ä»…æ’åºç”¨
sh_dictionary=read_txt_to_array('ä¸»é¢‘é“/shanghai.txt') #è¿‡æ»¤+æ’åº
ws_dictionary=read_txt_to_array('ä¸»é¢‘é“/å«è§†é¢‘é“.txt') #è¿‡æ»¤+æ’åº
ty_dictionary=read_txt_to_array('ä¸»é¢‘é“/ä½“è‚²é¢‘é“.txt') #è¿‡æ»¤
dy_dictionary=read_txt_to_array('ä¸»é¢‘é“/ç”µå½±.txt') #è¿‡æ»¤
dsj_dictionary=read_txt_to_array('ä¸»é¢‘é“/ç”µè§†å‰§.txt') #è¿‡æ»¤
gat_dictionary=read_txt_to_array('ä¸»é¢‘é“/æ¸¯æ¾³å°.txt') #è¿‡æ»¤
gj_dictionary=read_txt_to_array('ä¸»é¢‘é“/å›½é™…å°.txt') #è¿‡æ»¤
jlp_dictionary=read_txt_to_array('ä¸»é¢‘é“/çºªå½•ç‰‡.txt') #è¿‡æ»¤
dhp_dictionary=read_txt_to_array('ä¸»é¢‘é“/åŠ¨ç”»ç‰‡.txt') #è¿‡æ»¤
xq_dictionary=read_txt_to_array('ä¸»é¢‘é“/æˆæ›²é¢‘é“.txt') #è¿‡æ»¤
js_dictionary=read_txt_to_array('ä¸»é¢‘é“/è§£è¯´é¢‘é“.txt') #è¿‡æ»¤
cw_dictionary=read_txt_to_array('ä¸»é¢‘é“/æ˜¥æ™š.txt') #è¿‡æ»¤+æ’åº
mx_dictionary=read_txt_to_array('ä¸»é¢‘é“/æ˜æ˜Ÿ.txt') #è¿‡æ»¤
ztp_dictionary=read_txt_to_array('ä¸»é¢‘é“/ä¸»é¢˜ç‰‡.txt') #è¿‡æ»¤
zy_dictionary=read_txt_to_array('ä¸»é¢‘é“/ç»¼è‰ºé¢‘é“.txt') #è¿‡æ»¤
yy_dictionary=read_txt_to_array('ä¸»é¢‘é“/éŸ³ä¹é¢‘é“.txt') #è¿‡æ»¤
game_dictionary=read_txt_to_array('ä¸»é¢‘é“/æ¸¸æˆé¢‘é“.txt') #è¿‡æ»¤
radio_dictionary=read_txt_to_array('ä¸»é¢‘é“/æ”¶éŸ³æœºé¢‘é“.txt') #è¿‡æ»¤

zb_dictionary=read_txt_to_array('ä¸»é¢‘é“/ç›´æ’­ä¸­å›½.txt') #è¿‡æ»¤
mtv_dictionary=read_txt_to_array('ä¸»é¢‘é“/MTV.txt') #è¿‡æ»¤
Olympics_2024_Paris_dictionary=read_txt_to_array('ä¸»é¢‘é“/å¥¥è¿é¢‘é“.txt') #è¿‡æ»¤

zj_dictionary=read_txt_to_array('åœ°æ–¹å°/æµ™æ±Ÿé¢‘é“.txt') #è¿‡æ»¤
jsu_dictionary=read_txt_to_array('åœ°æ–¹å°/æ±Ÿè‹é¢‘é“.txt') #è¿‡æ»¤
gd_dictionary=read_txt_to_array('åœ°æ–¹å°/å¹¿ä¸œé¢‘é“.txt') #è¿‡æ»¤
hn_dictionary=read_txt_to_array('åœ°æ–¹å°/æ¹–å—é¢‘é“.txt') #è¿‡æ»¤
ah_dictionary=read_txt_to_array('åœ°æ–¹å°/å®‰å¾½é¢‘é“.txt') #è¿‡æ»¤
hain_dictionary=read_txt_to_array('åœ°æ–¹å°/æµ·å—é¢‘é“.txt') #è¿‡æ»¤
nm_dictionary=read_txt_to_array('åœ°æ–¹å°/å†…è’™é¢‘é“.txt') #è¿‡æ»¤
hb_dictionary=read_txt_to_array('åœ°æ–¹å°/æ¹–åŒ—é¢‘é“.txt') #è¿‡æ»¤
ln_dictionary=read_txt_to_array('åœ°æ–¹å°/è¾½å®é¢‘é“.txt') #è¿‡æ»¤
sx_dictionary=read_txt_to_array('åœ°æ–¹å°/é™•è¥¿é¢‘é“.txt') #è¿‡æ»¤
shanxi_dictionary=read_txt_to_array('åœ°æ–¹å°/å±±è¥¿é¢‘é“.txt') #è¿‡æ»¤
shandong_dictionary=read_txt_to_array('åœ°æ–¹å°/å±±ä¸œé¢‘é“.txt') #è¿‡æ»¤
yunnan_dictionary=read_txt_to_array('åœ°æ–¹å°/äº‘å—é¢‘é“.txt') #è¿‡æ»¤

##################ã€2024-07-30 18:04:56ã€‘
bj_dictionary=read_txt_to_array('åœ°æ–¹å°/åŒ—äº¬é¢‘é“.txt') #è¿‡æ»¤
cq_dictionary=read_txt_to_array('åœ°æ–¹å°/é‡åº†é¢‘é“.txt') #è¿‡æ»¤
fj_dictionary=read_txt_to_array('åœ°æ–¹å°/ç¦å»ºé¢‘é“.txt') #è¿‡æ»¤
gs_dictionary=read_txt_to_array('åœ°æ–¹å°/ç”˜è‚ƒé¢‘é“.txt') #è¿‡æ»¤
gx_dictionary=read_txt_to_array('åœ°æ–¹å°/å¹¿è¥¿é¢‘é“.txt') #è¿‡æ»¤
gz_dictionary=read_txt_to_array('åœ°æ–¹å°/è´µå·é¢‘é“.txt') #è¿‡æ»¤
heb_dictionary=read_txt_to_array('åœ°æ–¹å°/æ²³åŒ—é¢‘é“.txt') #è¿‡æ»¤
hen_dictionary=read_txt_to_array('åœ°æ–¹å°/æ²³å—é¢‘é“.txt') #è¿‡æ»¤
hlj_dictionary=read_txt_to_array('åœ°æ–¹å°/é»‘é¾™æ±Ÿé¢‘é“.txt') #è¿‡æ»¤
jl_dictionary=read_txt_to_array('åœ°æ–¹å°/å‰æ—é¢‘é“.txt') #è¿‡æ»¤
jx_dictionary=read_txt_to_array('åœ°æ–¹å°/æ±Ÿè¥¿é¢‘é“.txt') #è¿‡æ»¤
nx_dictionary=read_txt_to_array('åœ°æ–¹å°/å®å¤é¢‘é“.txt') #è¿‡æ»¤
qh_dictionary=read_txt_to_array('åœ°æ–¹å°/é’æµ·é¢‘é“.txt') #è¿‡æ»¤
sc_dictionary=read_txt_to_array('åœ°æ–¹å°/å››å·é¢‘é“.txt') #è¿‡æ»¤
tj_dictionary=read_txt_to_array('åœ°æ–¹å°/å¤©æ´¥é¢‘é“.txt') #è¿‡æ»¤
xj_dictionary=read_txt_to_array('åœ°æ–¹å°/æ–°ç–†é¢‘é“.txt') #è¿‡æ»¤

#è¯»å–çº é”™é¢‘é“åç§°æ–¹æ³•
def load_corrections_name(filename):
    corrections = {}
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split(',')
            correct_name = parts[0]
            for name in parts[1:]:
                corrections[name] = correct_name
    return corrections

#è¯»å–çº é”™æ–‡ä»¶
corrections_name = load_corrections_name('assets/corrections_name.txt')

#çº é”™é¢‘é“åç§°
#correct_name_data(corrections_name,xxxx)
def correct_name_data(corrections, data):
    corrected_data = []
    for line in data:
        name, url = line.split(',', 1)
        if name in corrections and name != corrections[name]:
            name = corrections[name]
        corrected_data.append(f"{name},{url}")
    return corrected_data



def sort_data(order, data):
    # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ¯è¡Œæ•°æ®çš„ç´¢å¼•
    order_dict = {name: i for i, name in enumerate(order)}
    
    # å®šä¹‰ä¸€ä¸ªæ’åºé”®å‡½æ•°ï¼Œå¤„ç†ä¸åœ¨ order_dict ä¸­çš„å­—ç¬¦ä¸²
    def sort_key(line):
        name = line.split(',')[0]
        return order_dict.get(name, len(order))
    
    # æŒ‰ç…§ order ä¸­çš„é¡ºåºå¯¹æ•°æ®è¿›è¡Œæ’åº
    sorted_data = sorted(data, key=sort_key)
    return sorted_data


# å¾ªç¯å¤„ç†æ¯ä¸ªURL
for url in urls:
    print(f"å¤„ç†URL: {url}")
    process_url(url)



# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œæå–æ¯è¡Œä¸­é€—å·å‰é¢çš„æ•°å­—éƒ¨åˆ†ä½œä¸ºæ’åºçš„ä¾æ®
def extract_number(s):
    num_str = s.split(',')[0].split('-')[1]  # æå–é€—å·å‰é¢çš„æ•°å­—éƒ¨åˆ†
    numbers = re.findall(r'\d+', num_str)   #å› ä¸ºæœ‰+å’ŒK
    return int(numbers[-1]) if numbers else 999
# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰æ’åºå‡½æ•°
def custom_sort(s):
    if "CCTV-4K" in s:
        return 2  # å°†åŒ…å« "4K" çš„å­—ç¬¦ä¸²æ’åœ¨åé¢
    elif "CCTV-8K" in s:
        return 3  # å°†åŒ…å« "8K" çš„å­—ç¬¦ä¸²æ’åœ¨åé¢ 
    elif "(4K)" in s:
        return 1  # å°†åŒ…å« " (4K)" çš„å­—ç¬¦ä¸²æ’åœ¨åé¢
    else:
        return 0  # å…¶ä»–å­—ç¬¦ä¸²ä¿æŒåŸé¡ºåº



#è¯»å–whitelist,æŠŠé«˜å“åº”æºä»ç™½åå•ä¸­æŠ½å‡ºåŠ å…¥merged_outputã€‚
whitelist_auto_lines=read_txt_to_array('blacklist/whitelist_auto.txt') #
for whitelist_line in whitelist_auto_lines:
    if  "#genre#" not in whitelist_line and "," in whitelist_line and "://" in whitelist_line:
        whitelist_parts = whitelist_line.split(",")
        try:
            response_time = float(whitelist_parts[0].replace("ms", ""))
        except ValueError:
            print(f"response_timeè½¬æ¢å¤±è´¥: {whitelist_line}")
            response_time = 60000  # å•ä½æ¯«ç§’ï¼Œè½¬æ¢å¤±è´¥ç»™ä¸ª60ç§’
        if response_time < 2000:  #2sä»¥å†…çš„é«˜å“åº”æº
            process_channel_line(",".join(whitelist_parts[1:]))


# åˆå¹¶æ‰€æœ‰å¯¹è±¡ä¸­çš„è¡Œæ–‡æœ¬ï¼ˆå»é‡ï¼Œæ’åºåæ‹¼æ¥ï¼‰
version=datetime.now().strftime("%Y%m%d-%H-%M-%S")+",url"
all_lines =  ["æ›´æ–°æ—¶é—´,#genre#"] +[version] + ['\n'] +\
             ["ğŸŒ¸å¥¥è¿é¢‘é“,#genre#"] + sort_data(Olympics_2024_Paris_dictionary,set(correct_name_data(corrections_name,Olympics_2024_Paris_lines))) + ['\n'] + \
             ["å¤®è§†é¢‘é“,#genre#"] + sort_data(ys_dictionary,set(correct_name_data(corrections_name,ys_lines))) + ['\n'] + \
             ["å«è§†é¢‘é“,#genre#"] + sort_data(ws_dictionary,set(correct_name_data(corrections_name,ws_lines))) + ['\n'] + \
             ["ä¸Šæµ·é¢‘é“,#genre#"] + sort_data(sh_dictionary,set(correct_name_data(corrections_name,sh_lines))) + ['\n'] + \
             ["ä½“è‚²é¢‘é“,#genre#"] + sort_data(ty_dictionary,set(correct_name_data(corrections_name,ty_lines))) + ['\n'] + \
             ["ç”µå½±é¢‘é“,#genre#"] + sort_data(dy_dictionary,set(correct_name_data(corrections_name,dy_lines))) + ['\n'] + \
             ["ç”µè§†å‰§é¢‘é“,#genre#"] + sort_data(dsj_dictionary,set(correct_name_data(corrections_name,dsj_lines))) + ['\n'] + \
             ["æ˜æ˜Ÿ,#genre#"] + sort_data(mx_dictionary,set(correct_name_data(corrections_name,mx_lines))) + ['\n'] + \
             ["ä¸»é¢˜ç‰‡,#genre#"] + sort_data(ztp_dictionary,set(correct_name_data(corrections_name,ztp_lines))) + ['\n'] + \
             ["æ¸¯æ¾³å°,#genre#"] + sort_data(gat_dictionary,set(correct_name_data(corrections_name,gat_lines))) + ['\n'] + \
             ["å›½é™…å°,#genre#"] + sort_data(gj_dictionary,set(correct_name_data(corrections_name,gj_lines))) + ['\n'] + \
             ["çºªå½•ç‰‡,#genre#"] + sort_data(jlp_dictionary,set(correct_name_data(corrections_name,jlp_lines)))+ ['\n'] + \
             ["åŠ¨ç”»ç‰‡,#genre#"] + sorted(set(dhp_lines)) + ['\n'] + \
             ["æˆæ›²é¢‘é“,#genre#"] + sort_data(xq_dictionary,set(correct_name_data(corrections_name,xq_lines))) + ['\n'] + \
             ["è§£è¯´é¢‘é“,#genre#"] + sorted(set(js_lines)) + ['\n'] + \
             ["ç»¼è‰ºé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,zy_lines))) + ['\n'] + \
             ["éŸ³ä¹é¢‘é“,#genre#"] + sorted(set(yy_lines)) + ['\n'] + \
             ["æ¸¸æˆé¢‘é“,#genre#"] + sorted(set(game_lines)) + ['\n'] + \
             ["Dï½œæµ™æ±Ÿé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,zj_lines))) + ['\n'] + \
             ["Dï½œæ±Ÿè‹é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,jsu_lines))) + ['\n'] + \
             ["Dï½œæ¹–å—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,hn_lines))) + ['\n'] + \
             ["Dï½œæ¹–åŒ—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,hb_lines))) + ['\n'] + \
             ["Dï½œå®‰å¾½é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,ah_lines))) + ['\n'] + \
             ["Dï½œå¹¿ä¸œé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,gd_lines))) + ['\n'] + \
             ["Dï½œæµ·å—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,hain_lines))) + ['\n'] + \
             ["Dï½œå†…è’™é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,nm_lines))) + ['\n'] + \
             ["Dï½œè¾½å®é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,ln_lines))) + ['\n'] + \
             ["Dï½œé™•è¥¿é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,sx_lines))) + ['\n'] + \
             ["Dï½œå±±è¥¿é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,shanxi_lines))) + ['\n'] + \
             ["Dï½œå±±ä¸œé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,shandong_lines))) + ['\n'] + \
             ["Dï½œäº‘å—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,yunnan_lines))) + ['\n'] + \
             ["Dï½œåŒ—äº¬é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,bj_lines))) + ['\n'] + \
             ["Dï½œé‡åº†é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,cq_lines))) + ['\n'] + \
             ["Dï½œç¦å»ºé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,fj_lines))) + ['\n'] + \
             ["Dï½œç”˜è‚ƒé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,gs_lines))) + ['\n'] + \
             ["Dï½œå¹¿è¥¿é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,gx_lines))) + ['\n'] + \
             ["Dï½œè´µå·é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,gz_lines))) + ['\n'] + \
             ["Dï½œæ²³åŒ—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,heb_lines))) + ['\n'] + \
             ["Dï½œæ²³å—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,hen_lines))) + ['\n'] + \
             ["Dï½œé»‘é¾™æ±Ÿé¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,hlj_lines))) + ['\n'] + \
             ["Dï½œå‰æ—é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,jl_lines))) + ['\n'] + \
             ["Dï½œæ±Ÿè¥¿é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,jx_lines))) + ['\n'] + \
             ["Dï½œå®å¤é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,nx_lines))) + ['\n'] + \
             ["Dï½œé’æµ·é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,qh_lines))) + ['\n'] + \
             ["Dï½œå››å·é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,sc_lines))) + ['\n'] + \
             ["Dï½œå¤©æ´¥é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,tj_lines))) + ['\n'] + \
             ["Dï½œæ–°ç–†é¢‘é“,#genre#"] + sorted(set(correct_name_data(corrections_name,xj_lines))) + ['\n'] + \
             ["æ˜¥æ™š,#genre#"] + sort_data(cw_dictionary,set(cw_lines))  + ['\n'] + \
             ["ç›´æ’­ä¸­å›½,#genre#"] + sorted(set(correct_name_data(corrections_name,zb_lines))) + ['\n'] + \
             ["MTV,#genre#"] + sorted(set(correct_name_data(corrections_name,mtv_lines))) + ['\n'] + \
             ["æ”¶éŸ³æœºé¢‘é“,#genre#"] + sort_data(radio_dictionary,set(radio_lines)) 


# å°†åˆå¹¶åçš„æ–‡æœ¬å†™å…¥æ–‡ä»¶
output_file = "merged_output.txt"
others_file = "others_output.txt"
try:
    with open(output_file, 'w', encoding='utf-8') as f:
        for line in all_lines:
            f.write(line + '\n')
    print(f"åˆå¹¶åçš„æ–‡æœ¬å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")

    with open(others_file, 'w', encoding='utf-8') as f:
        for line in other_lines:
            f.write(line + '\n')
    print(f"Otherså·²ä¿å­˜åˆ°æ–‡ä»¶: {others_file}")

except Exception as e:
    print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

################# æ·»åŠ ç”Ÿæˆm3uæ–‡ä»¶
# æŠ¥æ—¶
print(f"time: {datetime.now().strftime("%Y%m%d_%H_%M_%S")}")

channels_logos=read_txt_to_array('assets/logo.txt') #è¯»å…¥logoåº“
def get_logo_by_channel_name(channel_name):
    # éå†æ•°ç»„æŸ¥æ‰¾é¢‘é“åç§°
    for line in channels_logos:
        name, url = line.split(',')
        if name == channel_name:
            return url
    return None

output_text = "#EXTM3U x-tvg-url='https://live.fanmingming.com/e.xml'\n"

with open(output_file, "r", encoding='utf-8') as file:
    input_text = file.read()

lines = input_text.strip().split("\n")
group_name = ""
for line in lines:
    parts = line.split(",")
    if len(parts) == 2 and "#genre#" in line:
        group_name = parts[0]
    elif len(parts) == 2:
        channel_name = parts[0]
        channel_url = parts[1]
        logo_url=get_logo_by_channel_name(channel_name)
        if logo_url is None:  #not found logo
            output_text += f"#EXTINF:-1 group-title=\"{group_name}\",{channel_name}\n"
            output_text += f"{channel_url}\n"
        else:
            output_text += f"#EXTINF:-1  tvg-name=\"{channel_name}\" tvg-logo=\"{logo_url}\"  group-title=\"{group_name}\",{channel_name}\n"
            output_text += f"{channel_url}\n"

with open("merged_output.m3u", "w", encoding='utf-8') as file:
    file.write(output_text)

print("merged_output.m3uæ–‡ä»¶å·²ç”Ÿæˆã€‚")

# æ‰§è¡Œç»“æŸæ—¶é—´
timeend = datetime.now()

# è®¡ç®—æ—¶é—´å·®
elapsed_time = timeend - timestart
total_seconds = elapsed_time.total_seconds()

# è½¬æ¢ä¸ºåˆ†é’Ÿå’Œç§’
minutes = int(total_seconds // 60)
seconds = int(total_seconds % 60)
# æ ¼å¼åŒ–å¼€å§‹å’Œç»“æŸæ—¶é—´
timestart_str = timestart.strftime("%Y%m%d_%H_%M_%S")
timeend_str = timeend.strftime("%Y%m%d_%H_%M_%S")

print(f"å¼€å§‹æ—¶é—´: {timestart_str}")
print(f"ç»“æŸæ—¶é—´: {timeend_str}")
print(f"æ‰§è¡Œæ—¶é—´: {minutes} åˆ† {seconds} ç§’")

#å¤‡ç”¨1ï¼šhttp://tonkiang.us
#å¤‡ç”¨2ï¼š
#å¤‡ç”¨3ï¼š

